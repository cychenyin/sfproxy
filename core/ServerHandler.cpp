// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.

#include <boost/smart_ptr/shared_ptr.hpp>

#include <unistd.h>
#include <iostream>
#include <sstream>
#include <stdio.h>
#include <stdlib.h>

#include "ServerHandler.h"

namespace FinagleRegistryProxy {

// TODO ... re imple warm task
// init registry cache from file firstly, and then override these registry with zk if possible;
void WarmTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		vector<string> names = c->get_all_services(zk_root);
		vector<string>::iterator it = names.begin();
		while (it != names.end()) {
			if (c)
				c->get_service(*it);
			++it;
		}
		c->close();
	} else {
		logger::warn("fail to open zk client when warming. please check out whether zookeeper cluster is valid.");
		cout << "fail to open zk client when warming. please check out whether zookeeper cluster is valid" << endl;
	}
}

void RegisterTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		if (c->get_connected() == true) {
			stringstream ss;
			ss << "/soa";
			c->create_pnode(ss.str());
			ss << "/proxies";
			c->create_pnode(ss.str());
			ss << "/" << node_name;
			int res = c->create_enode(ss.str(), "");
			cout << "register self done. path=" << ss.str() << endl;
			if (res != 0) {
				logger::warn("register_self zoo_create error, path=%s", ss.str().c_str());
			}
		}
		c->close();
	} else {
		logger::warn("fail to open zk client registering self. please check out whether zookeeper cluster is valid.");
		cout << "fail to open zk client when registering self. please check out whether zookeeper cluster is valid" << endl;
	}
}

void ZkReadTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		c->get_service(zkpath);
		c->close(); // must
	} else {
		logger::warn("fail to open zk client when async get request: %s. pool exhausted maybe. ", zkpath.c_str());
	}
	skip_buf->erase(zkpath);
}

TaskScheduler::TaskScheduler(ServerHandler* _handler) {
	this->handler = _handler;
	assert(this->handler);
	stop_flag = false;
	interval_in_us = 10 * 1000;
	count = 0;
}

TaskScheduler::~TaskScheduler() {
	this->clear();

	this->handler = NULL;
}

void TaskScheduler::clear() {
	stop();

	TaskInfo *p = NULL;
	while (runners.size() > 0) {
		p = runners.back();
		runners.pop_back();
		delete p;
		p = NULL;
	}
}

void TaskScheduler::run() {
	stop_flag = false;
	while (!stop_flag) {
#ifdef DEBUG_
		cout << "scheduler running..." << endl;
#endif
		try {
			for (RunnerVector::iterator it = runners.begin(); it != runners.end(); ++it) {
				// verify stop signal firstly
				if (stop_flag) {
					cout << "1. scheduler stopped" << endl;
					return;
				}
				int32_t now = utils::now_in_ms();
				TaskInfo* task = *it;
				if (now > (task->interval_in_ms + task->last_run_ms)) {
					try {
						cout << "2.1 scheduler committing task " << task->name << endl;
						handler->commit_task(task);
						task->last_run_ms = now;
						cout << "2.2 scheduler committed task " << task->name << endl;
					} catch (const TooManyPendingTasksException &ex) {
						logger::warn("too many pending task in thread pool when committing scheduled task. %s", ex.what());
					}
				}
			}
		} catch (...) {
			cout << "TaskScheduler::run throw unknown exception"  << endl;
		}
		usleep(interval_in_us);
#ifdef DEBUG_
		cout << "scheduler has run." << endl;
#endif
	}
#ifdef DEBUG_
	cout << "scheduler quit " << endl;
#endif
}

void TaskScheduler::add(TaskInfo* _task) {
	stringstream ss;
	ss << "task" << ++count;
	_task->name = ss.str();
	runners.push_back(_task);
}

void TaskScheduler::add(ScheduledTask* _runner, int _interval_ms) {
	TaskInfo* info = new TaskInfo(_runner, _interval_ms);
	stringstream ss;
	ss << "task" << ++count;
	info->name = ss.str();
	runners.push_back(info);
}

// stop and wait
void TaskScheduler::stop() {
	stop_flag = true;
//	cout << "scheduler stopping" << endl;
#ifndef TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT
	usleep(this->interval_in_us * 2);
#else
	usleep((long)(this->interval_in_us * TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT));
	cout << "task scheduler stop wait timeout: " << (long)(this->interval_in_us * TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT) << endl;
#endif
//	cout << "scheduler stopped" << endl;
}

// TODO ... re imple reload task
// reload from zookeeper again, if all zk offline, then use local file
void ReloadTask::run() {
#ifdef DEBUG_
	cout << "reload task running..." << endl;
#endif
	try {
	// handler->warm();
	}catch(...){
	}
	cout << "reload task done. " << endl;
}

void AutoBreakZkConnTask::run() {
#ifdef DEBUG_
	cout << "auto break task running..." << endl;
#endif
//	pool->clear();
//	handler->register_self(); // have to do it
}

void AutoSaveTask::run() {
#ifdef DEBUG_
	cout << "auto save task running..." << endl;
#endif

//	if(handler->status()  == 0 ) { // save to file only if server works healthly
//		// handler->cache->save(filename);
//		handler->save(filename);
//	}
}

ServerHandler::ServerHandler(string _zkhosts, int _port) :
		zkhosts(_zkhosts), port(_port), thread_count(3), split("/") {
	root = new string("/soa/services");
	cache = new RegistryCache();
	pool = new ClientPool(new ZkClientFactory(_zkhosts, cache));
	init_thread_pool();
	async_wait_timeout = -1; // Return immediately if pending task count exceeds specified max
	async_exec_timeout = 1000;
	skip_buf = new SkipBuffer(async_exec_timeout);
	init_hostname();

	scheduler = new TaskScheduler(this);
	init_scheduledtask();
}

ServerHandler::~ServerHandler() {
	if (pool) {
		delete pool;
		pool = 0;
	}
	if (cache) {
		delete cache;
		cache = 0;
	}
	if (root) {
		delete root;
		root = 0;
	}
	delete skip_buf;
	skip_buf = 0;

	if (scheduler) {
		delete scheduler;
	}
	threadManager->stop();
}
// RegistryProxyIf::get
void ServerHandler::get(std::string& _return, const std::string& serviceName) {
#ifdef DEBUG_

	uint64_t start = utils::now_in_us();
	uint64_t got(start), zk_retrieve_start(start), zk_retrieve_end(start), serial(start);
#endif
	string path = *root + split + serviceName;
	vector<Registry>* pvector = cache->get(path.c_str());
	if (pvector == 0 || pvector->size() == 0) { // not hit cache, then update cache
#ifdef DEBUG_
		zk_retrieve_start = utils::now_in_us();
#endif
		// if getting from zk, then skip
		pair<map<string, uint32_t>::iterator, bool> insert = skip_buf->insert(path);
		if (insert.second) {
			try {
				threadManager->add(shared_ptr<ZkReadTask>(new ZkReadTask(pool, path, skip_buf)), async_wait_timeout);
				// (new ZkReadTask(pool, path, skip_buf))->run();
			} catch (const TooManyPendingTasksException &ex) {
				logger::warn("too many pending zk task in thread pool. %s", ex.what());
			}
		}
#ifdef DEBUG_
		zk_retrieve_end = utils::now_in_us();
#endif
	}
#ifdef DEBUG_
	got = utils::now_in_us();
#endif
	if (pvector && pvector->size() > 0) {
		_return = Registry::serialize(*pvector);
	} else
		_return = "";
#ifdef DEBUG_
	serial = utils::now_in_us();
	cout << " pool total=" << pool->size() << " used=" << pool->used() << " idle=" << pool->idle() << endl;
	cout << " get total cost=" << DiffMs(serial, start) << " got=" << DiffMs(got, start) << " zk retrieve="
			<< DiffMs(zk_retrieve_end, zk_retrieve_start) << " serial=" << DiffMs(serial, got) << endl;
	// cache->dump();
#endif
}

// RegistryProxyIf::remove
void ServerHandler::remove(std::string& _return, const std::string& serviceName, const std::string& host, const int32_t port) {
	_return = "not supported now.";
	// cout << "remove called. " << endl;
}

// RegistryProxyIf::dump
void ServerHandler::dump(std::string& _return) {
	stringstream ss;
	ss << "frproxy dump info. " << "hostname:" << hostname << "; zkhosts:" << this->zkhosts << endl << endl;
	ss << "connection:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << pool->stat() << endl;

	ss << "cache:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << cache->dump() << endl;

	ss << "threads:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << "worker count:" << threadManager->workerCount() << endl;
	ss << "worker idle:" << threadManager->idleWorkerCount() << endl;
	ss << "expired task:" << threadManager->expiredTaskCount() << endl;
	ss << "pending task:" << threadManager->pendingTaskCount() << endl;
	ss << "pending max:" << threadManager->pendingTaskCountMax() << endl;

	ss << "skip buffer:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << skip_buf->dump() << endl;

	_return = ss.str();
}

// RegistryProxyIf::reset
void ServerHandler::reset(std::string& _return) {
	this->pool->clear(); // thread safe
	register_self();
	warm();
}
// RegistryProxyIf::status
int32_t ServerHandler::status() {
	int32_t ret = 0; // success
	ret += (pool->size() == 0 ? 1 : 0);
	ret += (pool->watcher_size() < 2 ? 2 : 0); // should watch service root /soa/serives/ and self /soa/proxies/.. at least
	ret += (cache->size() == 0 ? 4 : 0);
	ret += (threadManager->workerCount() < thread_count ? 8 : 0);
	return ret;
}

void ServerHandler::save(string& filename) {
	this->cache->save(filename);
}
void ServerHandler::warm() {
//		string path = "/soa/services/testservice";
//		Runnable *t = new ZkReadTask(pool, path, skip_buf);
//		t->run();
//		delete t;
//		t = 0;
//
//		t = new WarmTask(pool, *root);
//		t->run();
//		delete t;
//		t = 0;

	threadManager->add(shared_ptr<WarmTask>(new WarmTask(pool, *root)));
	logger::warn("warm server committed. server is getting up");
}

void ServerHandler::register_self() {
	stringstream name;
	name << this->hostname << ":" << port;
	try {
		threadManager->add(shared_ptr<RegisterTask>(new RegisterTask(pool, name.str())));
		logger::warn("server register self committed. ");
	} catch (const TooManyPendingTasksException &e) {
		logger::warn("too many pending task occured  in thread pool when register self. %s", e.what());
	}
}

void ServerHandler::start_scheduler() {
	try {
		// expiration is not expire, and wait forever
		threadManager->add(shared_ptr<TaskScheduler>(scheduler), 0, 0);

	} catch (const TooManyPendingTasksException &ex) {
		logger::warn("too many pending zk task in thread pool. %s", ex.what());
	}
}
// commit task with timeout
void ServerHandler::commit_task(TaskInfo* envlope) {
	// v1
	// threadManager->add(shared_ptr<Runnable>(task->runner), async_wait_timeout);
	// v2
//	shared_ptr<ScheduledTask> task(envlope->runner);
//	threadManager->add(task, async_wait_timeout);
	// v3
	threadManager->add(envlope->runner, async_wait_timeout);
}

void ServerHandler::init_scheduledtask() {
	ReloadTask *reload = new ReloadTask(this);
	AutoBreakZkConnTask *autobreak = new AutoBreakZkConnTask(this, this->pool);
	AutoSaveTask *autosave = new AutoSaveTask(this, "/tmp/frproxy.cache");

//	scheduler->add(reset, 3600 * 1000); // 1 hour
//	scheduler->add(autobreak, 24 * 3600 * 1000); // 1 hour
//	scheduler->add(autosave, 5 * 60 * 1000); // 1 hour

	scheduler->add(reload, 1 * 100); // 1 hour
	scheduler->add(autobreak, 1 * 100); // 1 hour
	//	scheduler->add(autosave, 5 * 60 * 1000); // 1 hour
}

void ServerHandler::init_thread_pool() {
	threadManager = ThreadManager::newSimpleThreadManager(3, 100);
	shared_ptr<PosixThreadFactory> threadFactory = shared_ptr<PosixThreadFactory>(new PosixThreadFactory());
	threadManager->threadFactory(threadFactory);
	threadManager->start();
}

void ServerHandler::init_hostname() {
	int size = 128;
	char *buf = new char[size];
	for (int i = 0; i < size; i++) {
		buf[i] = 0;
	}
	gethostname(buf, size);
	// copy to string
	this->hostname = string(buf);
	delete buf;
	buf = 0;
}

} /* namespace FinagleRegistryProxy  */
