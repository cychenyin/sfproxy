// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.

#include <boost/smart_ptr/shared_ptr.hpp>

#include <unistd.h>
#include <iostream>
#include <sstream>
#include <stdio.h>
#include <stdlib.h>

#include "ServerHandler.h"

// using namespace boost::static_pointer_cast;
namespace FinagleRegistryProxy {

// TODO ... re imple warm task
// init registry cache from file firstly, and then override these registry with zk if possible;
void WarmTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		vector<string> names = c->get_all_services(zk_root);
		vector<string>::iterator it = names.begin();
		while (it != names.end()) {
			if (c)
				c->get_service(*it);
			++it;
		}
		c->close();
	} else {
		logger::warn("fail to open zk client when warming. please check out whether zookeeper cluster is valid.");
		cout << "fail to open zk client when warming. please check out whether zookeeper cluster is valid" << endl;
	}
}

void RegisterTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		if (c->get_connected() == true) {
			stringstream ss;
			ss << "/soa";
			c->create_pnode(ss.str());
			ss << "/proxies";
			c->create_pnode(ss.str());
			ss << "/" << node_name;
			int res = c->create_enode(ss.str(), "");
			cout << "register self done. path=" << ss.str() << endl;
			if (res != 0) {
				logger::warn("register_self zoo_create error, path=%s", ss.str().c_str());
			}
		}
		c->close();
	} else {
		logger::warn("fail to open zk client registering self. please check out whether zookeeper cluster is valid.");
		cout << "fail to open zk client when registering self. please check out whether zookeeper cluster is valid" << endl;
	}
}

void ZkReadTask::run() {
	c = (ZkClient*) pool->open();
	if (c) {
		c->get_service(zkpath);
		c->close(); // must
	} else {
		logger::warn("fail to open zk client when async get request: %s. pool exhausted maybe. ", zkpath.c_str());
	}
	skip_buf->erase(zkpath);
}

TaskScheduler::TaskScheduler(shared_ptr<ServerHandler> _handler) {
	this->handler = _handler;
	assert(this->handler.get());

	stop_flag = false;
	interval_in_us = 10 * 1000;
	count = 0;
	first_delay_sec  = 1;
}

TaskScheduler::~TaskScheduler() {
	this->clear();
}

void TaskScheduler::clear() {
	stop();
	runners.clear();
}

void TaskScheduler::run() {
	stop_flag = false;
	if(first_delay_sec > 0) {
		sleep(first_delay_sec);
	}

	while (!stop_flag) {
		for (TaskVector::iterator it = runners.begin(); it != runners.end(); ++it) {
			uint32_t now = utils::now_in_ms();
			//TaskInfo* task = *it;
			shared_ptr<ScheduledTask> task = *it;
			cout << utils::now() << " " << task->name << " busy="<< task->busy << " now=" << now << " last=" << task->interval_in_ms + task->last_run_ms << " diff=" << now - task->last_run_ms - task->interval_in_ms<< endl;
			if (task->busy == false && now - task->last_run_ms - task->interval_in_ms > 0) {
				try {
					task->busy = true; // set flag before commit
					handler->commit_task(task);
				} catch (const TooManyPendingTasksException &ex) {
					logger::warn("TaskScheduler::run exception, too many pending task in thread pool when committing %s task. %s", task->name.c_str(), ex.what());
					task->busy = false;
				} catch (const exception& ex) {
					logger::warn("TaskScheduler::run %s exception: %s", task->name.c_str(), ex.what());
					cerr << "TaskScheduler::run " << task->name << " exception: " << ex.what() << endl;
					task->busy = false;
				} catch (const char* ex) {
					logger::warn("TaskScheduler::run %s exception, msg: %s", task->name.c_str(), ex);
					cerr << "TaskScheduler::run " << task->name << " exception, msg:" << ex << endl;
					task->busy = false;
				} catch (...) {
					logger::warn("TaskScheduler::run %s fail, and eated exception.", task->name.c_str());
					cerr << "TaskScheduler::run " << task->name << " fail, and eated exception." << endl;
					task->busy = false;
				}
			}
		}
		usleep(interval_in_us);
	}
#ifdef DEBUG_
	cout << "scheduler quit" << endl;
#endif
}

void TaskScheduler::add(shared_ptr<ScheduledTask> _runner) {
	runners.push_back(_runner);
}

// stop and wait
void TaskScheduler::stop() {
	stop_flag = true;
	for (TaskVector::iterator it = runners.begin(); it != runners.end(); ++it) {
		(*it)->busy = false;
	}
#ifndef TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT
	usleep(this->interval_in_us * 2);
#else
	usleep((long)(this->interval_in_us * TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT));
	cout << "task scheduler stop wait timeout: " << (long)(this->interval_in_us * TASKSCHEDULER_STOP_WAIT_PERIOD_COUNT) << endl;
#endif
}

string ScheduledTask::tostring() const {
	stringstream ss;
	ss << "\t" << name << "\t" << interval_in_ms << "" << last_run_ms << "" << endl;
	return ss.str();
}
// run task, make sure no exception throw out
void ScheduledTask::run() {
	cout << name << " \ttask running..." << endl;
#ifdef DEBUG_
#endif
	try {
		dorun();
	} catch (const exception& ex) {
		cout << "ScheduledTask " << name << " exception cause of " << ex.what() << endl;
	} catch (const char* e) {
		cout << "ScheduledTask" << name << " exception cause of " << e << endl;
	} catch (...) {
		cout << "ScheduledTask" << name << " failed" << endl;
	}
	last_run_ms = utils::now_in_ms();
	busy = false;
}

// TODO ... re imple reload task
// reload from zookeeper again, if all zk offline, then use local file
void ResetTask::dorun() {
	try {
		string result;
		handler->reset(result);

	} catch (...) {
	}
}

void AutoBreakZkConnTask::dorun() {
	pool->clear();
	handler->register_self(); // have to do it
}

void AutoSaveTask::dorun() {
	if(handler->status()  == 0 ) { // save to file only if server works healthly
		handler->save(filename);
	}
}

ServerHandler::ServerHandler(string _zkhosts, int _port) :
		zkhosts(_zkhosts), port(_port), thread_count(3), split("/") {
	root = new string("/soa/services");
	cache = new RegistryCache();
	pool = new ClientPool(new ZkClientFactory(_zkhosts, cache));
	init_thread_pool();
	async_wait_timeout = -1; // Return immediately if pending task count exceeds specified max
	async_exec_timeout = 1000;
	skip_buf = new SkipBuffer(async_exec_timeout);
	init_hostname();

	// use shared_from_this, so, CAN NOT initialize scheduler in constructor
	// init_scheduledtask();
}

ServerHandler::~ServerHandler() {
	if (pool) {
		delete pool;
		pool = 0;
	}
	if (cache) {
		delete cache;
		cache = 0;
	}
	if (root) {
		delete root;
		root = 0;
	}
	delete skip_buf;
	skip_buf = 0;

	if (scheduler) {
		delete scheduler;
	}
	threadManager->stop();
}
// RegistryProxyIf::get
void ServerHandler::get(std::string& _return, const std::string& serviceName) {
#ifdef DEBUG_

	uint64_t start = utils::now_in_us();
	uint64_t got(start), zk_retrieve_start(start), zk_retrieve_end(start), serial(start);
#endif
	string path = *root + split + serviceName;
	vector<Registry>* pvector = cache->get(path.c_str());
	if (pvector == 0 || pvector->size() == 0) { // not hit cache, then update cache
#ifdef DEBUG_
		zk_retrieve_start = utils::now_in_us();
#endif
		// if getting from zk, then skip
		pair<map<string, uint32_t>::iterator, bool> insert = skip_buf->insert(path);
		if (insert.second) {
			try {
				threadManager->add(shared_ptr<Runnable>(new ZkReadTask(pool, path, skip_buf)), async_wait_timeout);
				// (new ZkReadTask(pool, path, skip_buf))->run();
			} catch (const TooManyPendingTasksException &ex) {
				logger::warn("too many pending zk task in thread pool. %s", ex.what());
			}
		}
#ifdef DEBUG_
		zk_retrieve_end = utils::now_in_us();
#endif
	}
#ifdef DEBUG_
	got = utils::now_in_us();
#endif
	if (pvector && pvector->size() > 0) {
		_return = Registry::serialize(*pvector);
	} else
		_return = "";
#ifdef DEBUG_
	serial = utils::now_in_us();
	cout << " pool total=" << pool->size() << " used=" << pool->used() << " idle=" << pool->idle() << endl;
	cout << " get total cost=" << DiffMs(serial, start) << " got=" << DiffMs(got, start) << " zk retrieve="
			<< DiffMs(zk_retrieve_end, zk_retrieve_start) << " serial=" << DiffMs(serial, got) << endl;
	// cache->dump();
#endif
}

// RegistryProxyIf::remove
void ServerHandler::remove(std::string& _return, const std::string& serviceName, const std::string& host, const int32_t port) {
	_return = "not supported now.";
	// cout << "remove called. " << endl;
}

// RegistryProxyIf::dump
void ServerHandler::dump(std::string& _return) {
	stringstream ss;
	ss << "frproxy dump info. " << "hostname:" << hostname << "; zkhosts:" << this->zkhosts << endl << endl;
	ss << "connection:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << pool->stat() << endl;

	ss << "cache:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << cache->dump() << endl;

	ss << "threads:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << "worker count:" << threadManager->workerCount() << endl;
	ss << "worker idle:" << threadManager->idleWorkerCount() << endl;
	ss << "expired task:" << threadManager->expiredTaskCount() << endl;
	ss << "pending task:" << threadManager->pendingTaskCount() << endl;
	ss << "pending max:" << threadManager->pendingTaskCountMax() << endl;

	ss << "skip buffer:" << endl;
	ss << "\n---------------------------------------------" << endl;
	ss << skip_buf->dump() << endl;

	_return = ss.str();
}


// RegistryProxyIf::reset
void ServerHandler::reset(std::string& _return) {
	this->pool->clear(); // thread safe
	this->init_scheduledtask();
	this->cache->clear();

	this->threadManager->stop(); // needed ?
	this->threadManager->start(); // needed ?

	register_self();
	warm();

	stringstream ss;
	int res = status();
	switch(res) {
	case 1:
		ss << "fail to create zk conn " << endl;
		break;
	case 2:
		ss << "none watcher created" << endl;
		break;
	case 3:
		ss << "no service configured" << endl;
		break;
	case 4:
		ss << "unable to create enought thread " << endl;
		break;
	default:
		break;
	}

	_return = ss.str();
}
// RegistryProxyIf::status
int32_t ServerHandler::status() {
	int32_t ret = 0; // success
	ret += (pool->size() == 0 ? 1 : 0);
	ret += (pool->watcher_size() < 2 ? 2 : 0); // should watch service root /soa/serives/ and self /soa/proxies/.. at least
	ret += (cache->size() == 0 ? 4 : 0);
	ret += (threadManager->workerCount() < thread_count ? 8 : 0);
	return ret;
}

void ServerHandler::save(string& filename) {
	this->cache->save(filename);
}
void ServerHandler::async_warm() {
//		string path = "/soa/services/testservice";
//		Runnable *t = new ZkReadTask(pool, path, skip_buf);
//		t->run();
//		delete t;
//		t = 0;
//
//		t = new WarmTask(pool, *root);
//		t->run();
//		delete t;
//		t = 0;


	threadManager->add(shared_ptr<Runnable>(new WarmTask(pool, *root)));
	logger::warn("warm server committed. server is getting up");
}

void ServerHandler::warm() {

}

void ServerHandler::register_self() {

}
void ServerHandler::async_register_self() {
	stringstream name;
	name << this->hostname << ":" << port;
	try {
		threadManager->add(shared_ptr<Runnable>(new RegisterTask(pool, name.str())));
		logger::warn("server register self committed. ");
	} catch (const TooManyPendingTasksException &e) {
		logger::warn("too many pending task occured  in thread pool when register self. %s", e.what());
	}
}

void ServerHandler::start_scheduler() {
	if (scheduler == NULL) {
		init_scheduledtask();
	}
	try {
		// expiration is not expire, and wait forever
		threadManager->add(shared_ptr<TaskScheduler>(scheduler), 0, 0);

	} catch (const TooManyPendingTasksException &ex) {
		logger::warn("too many pending zk task in thread pool. %s", ex.what());
	}
}
// commit task with timeout
void ServerHandler::commit_task(shared_ptr<ScheduledTask> task) {
	// v1
	// threadManager->add(shared_ptr<Runnable>(task->runner), async_wait_timeout);
	// v2
//	shared_ptr<ScheduledTask> task(envlope->runner);
//	threadManager->add(task, async_wait_timeout);
	// v3
	// threadManager->add(envlope->runner, async_wait_timeout);
	// v4
	threadManager->add(task, 500, 500); // 10ms wait to add task to pending queue // 200ms expiration in execution
}

void ServerHandler::init_scheduledtask() {
	if(scheduler == NULL)
		scheduler = new TaskScheduler(this->shared_from_this());
	else
		scheduler->clear();
	shared_ptr<AutoSaveTask> autosave(
			new AutoSaveTask(this->shared_from_this(), string("autosave"), 3600 * 1000, "/tmp/frproxy.cache"));
	shared_ptr<ScheduledTask> reset(new ResetTask(this->shared_from_this(), string("reset"), 24 * 3600 * 1000));
	shared_ptr<AutoBreakZkConnTask> autobreak(
			new AutoBreakZkConnTask(this->shared_from_this(), string("autobreak"), 5 * 60 * 1000, this->pool));

	// TODO ... delete 6 lines followed
	reset->interval_in_ms = 100;
	autobreak->interval_in_ms = 100;
	autosave->interval_in_ms = 100;

	cout << reset->name << reset->interval_in_ms << endl;
	cout << autobreak->name << autobreak->interval_in_ms << endl;
	cout << autosave->name << autosave->interval_in_ms << endl;

	scheduler->add(autobreak);
	scheduler->add(autosave);
	scheduler->add(reset);
}

void ServerHandler::init_thread_pool() {
	threadManager = ThreadManager::newSimpleThreadManager(3, 100);
	shared_ptr<PosixThreadFactory> threadFactory = shared_ptr<PosixThreadFactory>(new PosixThreadFactory());
	threadManager->threadFactory(threadFactory);
	threadManager->start();
}

void ServerHandler::init_hostname() {
	int size = 128;
	char *buf = new char[size];
	for (int i = 0; i < size; i++) {
		buf[i] = 0;
	}
	gethostname(buf, size);
	// copy to string
	this->hostname = string(buf);
	delete buf;
	buf = 0;
}

} /* namespace FinagleRegistryProxy  */
